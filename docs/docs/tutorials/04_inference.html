
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Online Inference &#8212; SmartSim 0.3.2+dev.392cff4 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=84ace793992934648b4de8eed757e5a2" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/sphinx-book-theme.9d8b4a8b9bb19db25eeaddc40d639ba2.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Online training with SmartSim" href="05_training.html" />
    <link rel="prev" title="Online Analysis" href="03_lattice_boltz_analysis.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<div class="col-12 col-md-3 bd-sidebar site-navigation " id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">SmartSim 0.3.2+dev.392cff4 documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Overview of SmartSim
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../overview.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../community.html">
   Community
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_getting_started/01_getting_started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_using_clients.html">
   Using SmartRedis Clients
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_lattice_boltz_analysis.html">
   Online Analysis
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Online Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_training.html">
   Online training with SmartSim
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_starting_ray/06_starting_ray_builtin.html">
   Setting up a Ray Cluster
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  SmartSim
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../experiment.html">
   Experiments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../orchestrator.html">
   Orchestrator
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../launchers.html">
   Launchers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../api/smartsim_api.html">
   SmartSim API
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  SmartRedis
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../smartredis.html">
   SmartRedis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../sr_data_structures.html">
   Data Structures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../sr_runtime.html">
   Runtime Requirements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../api/smartredis_api.html">
   SmartRedis API
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../code_of_conduct.html">
   Code of Conduct
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../developer.html">
   Developer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../changelog.html">
   Changelog
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<!-- This is an invisible pixel that we watch to see if we've scrolled. -->
<div class="sbt-scroll-pixel-helper"></div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            <div class="topbar-left">
                
                <label class="nav-toggle-button" for="__navigation">
                    <div class="visually-hidden">Toggle navigation</div>
                    <i class="fas fa-bars"></i>
                </label>
                
            </div>
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/tutorials/04_inference.rst.txt"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.rst</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#your-first-inference-session">
   4.1 Your First Inference Session
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pytorch">
   4.2 PyTorch
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tensorflow-and-keras">
   4.2 TensorFlow and Keras
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#onnx">
   4.3 ONNX
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kmeans">
     KMeans
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-forest">
     Random Forest
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Online Inference</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#your-first-inference-session">
   4.1 Your First Inference Session
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pytorch">
   4.2 PyTorch
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tensorflow-and-keras">
   4.2 TensorFlow and Keras
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#onnx">
   4.3 ONNX
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kmeans">
     KMeans
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-forest">
     Random Forest
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <section id="online-inference">
<h1>Online Inference<a class="headerlink" href="#online-inference" title="Permalink to this headline">¶</a></h1>
<p>Compiling TensorFlow or PyTorch runtimes into each existing simulation is
difficult. Maintaining that type of integration with the rapidly growing and changing
APIs of libraries like TensorFlow and PyTorch is even more difficult.</p>
<p>Instead of forcing dependencies on the simulation code, SmartSim itself maintains those dependencies
and provides simulations runtime access to them through the <code class="docutils literal notranslate"><span class="pre">Orchestrator</span></code> database.</p>
<p>Simulations in Fortran, C, C++ and Python can call into PyTorch, TensorFlow,
and any library that supports the ONNX format without compiling in ML libraries into the
simulation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>While the SmartRedis examples below are written in Python, SmartRedis is implemented
in C, C++ and Fortran as well. Fortran, C, and C++ applications can all call the
same Machine Learning libraries/models as the examples below.</p>
</aside>
<section id="your-first-inference-session">
<h2>4.1 Your First Inference Session<a class="headerlink" href="#your-first-inference-session" title="Permalink to this headline">¶</a></h2>
<p id="infrastructure-code">SmartSim performs online inference by using the SmartRedis clients to call into the
Machine Learning runtimes linked into the Orchestrator database.</p>
<p>Therefore, to perform inference, you must first create an Orchestrator database and
launch it. The code below can be used to launch a database with SmartSim and Python
script that uses the SmartRedis Python client to perform innovations of the ML runtimes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">smartsim</span> <span class="kn">import</span> <span class="n">Experiment</span>
<span class="kn">from</span> <span class="nn">smartsim.database</span> <span class="kn">import</span> <span class="n">Orchestrator</span>

<span class="n">exp</span> <span class="o">=</span> <span class="n">Experiment</span><span class="p">(</span><span class="s2">&quot;inference-session&quot;</span><span class="p">,</span> <span class="n">launcher</span><span class="o">=</span><span class="s2">&quot;local&quot;</span><span class="p">)</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">Orchestrator</span><span class="p">(</span><span class="n">port</span><span class="o">=</span><span class="mi">6780</span><span class="p">)</span>

<span class="n">script</span> <span class="o">=</span> <span class="s2">&quot;inference.py&quot;</span>
<span class="n">settings</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">create_run_settings</span><span class="p">(</span><span class="s2">&quot;python&quot;</span><span class="p">,</span> <span class="n">exe_args</span><span class="o">=</span><span class="n">script</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span><span class="s2">&quot;model_using_ml&quot;</span><span class="p">,</span> <span class="n">settings</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">attach_generator_files</span><span class="p">(</span><span class="n">to_copy</span><span class="o">=</span><span class="n">script</span><span class="p">)</span>

<span class="n">exp</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="n">db</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">block</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">summary</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">exp</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="n">db</span><span class="p">)</span>
</pre></div>
</div>
<p>The above script will first launch the database, and then the Python script
containing the SmartRedis client code. The code here could easily be adapted to
launch a C, C++, or Fortran application containing the SmartRedis clients in
those languages as well.</p>
<p>Below are a few examples of scripts that could be used with the above
code to perform online inference with various ML backends supported
by SmartSim.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Online inference is not online training.
The following code examples do not include code to train the models shown.</p>
</aside>
</section>
<section id="pytorch">
<h2>4.2 PyTorch<a class="headerlink" href="#pytorch" title="Permalink to this headline">¶</a></h2>
<p>The Orchestrator supports both <a class="reference external" href="https://pytorch.org/">PyTorch</a> models and <a class="reference external" href="https://pytorch.org/docs/stable/jit.html">TorchScript</a> functions and scripts
in <a class="reference external" href="https://pytorch.org/">PyTorch</a> 1.7.1. To use ONNX in SmartSim, specify
<code class="docutils literal notranslate"><span class="pre">TORCH</span></code> as the argument for <em>backend</em> in the call to <code class="docutils literal notranslate"><span class="pre">client.set_model</span></code> or
<code class="docutils literal notranslate"><span class="pre">client.set_model_from_file</span></code>.</p>
<p>The below script can be used with the <a class="reference internal" href="#infrastructure-code"><span class="std std-ref">SmartSim code</span></a>
above to launch an inference session with a PyTorch model.</p>
<p>First, a PyTorch model is defined.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">smartredis</span> <span class="kn">import</span> <span class="n">Client</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">9216</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
<p>Next we create a function to “jit-trace” the model and save it to a buffer.
If you aren’t familiar with the concept of tracing, take a look at the
Torch documentation for <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html#torch.jit.trace">trace</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">example_forward_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_torch_model</span><span class="p">(</span><span class="n">torch_module</span><span class="p">,</span> <span class="n">example_forward_input</span><span class="p">):</span>

    <span class="c1"># perform the trace of the nn.Module.forward() method</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">torch_module</span><span class="p">,</span> <span class="n">example_forward_input</span><span class="p">)</span>

    <span class="c1"># save the traced module to a buffer</span>
    <span class="n">model_buffer</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">model_buffer</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model_buffer</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span>
</pre></div>
</div>
<dl class="simple">
<dt>Lastly, we use the SmartRedis Python client to</dt><dd><ol class="arabic simple">
<li><p>Connect to the database</p></li>
<li><p>Put a batch of 20 tensors into the database  (<code class="docutils literal notranslate"><span class="pre">put_tensor</span></code>)</p></li>
<li><p>Set the Torch model in the database (<code class="docutils literal notranslate"><span class="pre">set_model</span></code>)</p></li>
<li><p>Run the model on the batch of tensors (<code class="docutils literal notranslate"><span class="pre">run_model</span></code>)</p></li>
<li><p>Retrieve the result (<code class="docutils literal notranslate"><span class="pre">get_tensor</span></code>)</p></li>
</ol>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">cluster</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">client</span><span class="o">.</span><span class="n">put_tensor</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

<span class="c1"># put the PyTorch CNN in the database in GPU memory</span>
<span class="n">client</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="s2">&quot;cnn&quot;</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="s2">&quot;TORCH&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;GPU&quot;</span><span class="p">)</span>

<span class="c1"># execute the model, supports a variable number of inputs and outputs</span>
<span class="n">client</span><span class="o">.</span><span class="n">run_model</span><span class="p">(</span><span class="s2">&quot;cnn&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">])</span>

<span class="c1"># get the output</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediction: </span><span class="si">{</span><span class="n">output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Since we are launching the inference
script through SmartSim, we do not need to specify the address of the
database as SmartSim will connect the Client for us. Additionally,
<code class="docutils literal notranslate"><span class="pre">cluster=False</span></code> is specified so the client will not attempt to find
other cluster shards on the network.</p>
<p>If running on CPU, be sure to change the argument in the <code class="docutils literal notranslate"><span class="pre">set_model</span></code> call
above to <code class="docutils literal notranslate"><span class="pre">CPU</span></code>.</p>
</section>
<section id="tensorflow-and-keras">
<h2>4.2 TensorFlow and Keras<a class="headerlink" href="#tensorflow-and-keras" title="Permalink to this headline">¶</a></h2>
<p>The Orchestrator, in addition to PyTorch, is built with <a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a> and <a class="reference external" href="https://keras.io/">Keras</a> support by default.
Currently TensorFlow 2.5.2 is supported, but the graph of the model must be frozen
before it is placed in the database. This is the same process for both Keras and
TensorFlow.</p>
<p>The example below shows how to prepare a simple Keras model for use with SmartSim.
This script can be used with the <a class="reference internal" href="#infrastructure-code"><span class="std std-ref">SmartSim code</span></a>
above to launch an inference session with a TensorFlow or Keras model.</p>
<p>First, a simple Keras Convolutional Neural Network is defined.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>

<span class="c1"># create a simple Fully connected network in Keras</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">=</span><span class="p">[</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">),</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;flatten&quot;</span><span class="p">),</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;dense&quot;</span><span class="p">),</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;FCN&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Compile model with optimizer</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
            <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
            <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>After a model is created (trained or not), the graph of the model is
frozen saved to file so the client method <code class="docutils literal notranslate"><span class="pre">client.set_model_from_file</span></code>
can load it into the database.</p>
<p>SmartSim includes a utility to freeze the graph of a TensorFlow or Keras model in
<a class="reference internal" href="../api/smartsim_api.html#smartsim-tf-api"><span class="std std-ref">smartsim.tf</span></a>. To use TensorFlow or Keras in SmartSim, specify
<code class="docutils literal notranslate"><span class="pre">TF</span></code> as the argument for <em>backend</em> in the call to <code class="docutils literal notranslate"><span class="pre">client.set_model</span></code> or
<code class="docutils literal notranslate"><span class="pre">client.set_model_from_file</span></code>.</p>
<p>Note that TensorFlow and Keras, unlike the other ML libraries supported by
SmartSim, requires an <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">output</span></code> argument in the call to
<code class="docutils literal notranslate"><span class="pre">set_model</span></code>. These arguments correspond to the layer names of the
created model. The <a class="reference internal" href="../api/smartsim_api.html#smartsim-tf-api"><span class="std std-ref">smartsim.tf.freeze_model</span></a> utility
returns these values for convenience as shown below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">smartredis</span> <span class="kn">import</span> <span class="n">Client</span>
<span class="kn">from</span> <span class="nn">smartsim.tf</span> <span class="kn">import</span> <span class="n">freeze_model</span>

<span class="c1"># SmartSim utility for Freezing the model</span>
<span class="n">model_path</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">freeze_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s2">&quot;fcn.pb&quot;</span><span class="p">)</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">cluster</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># TensorFlow backed requires named inputs and outputs on graph</span>
<span class="c1"># this differs from PyTorch and ONNX.</span>
<span class="n">client</span><span class="o">.</span><span class="n">set_model_from_file</span><span class="p">(</span>
    <span class="s2">&quot;keras_fcn&quot;</span><span class="p">,</span> <span class="n">model_path</span><span class="p">,</span> <span class="s2">&quot;TF&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span>
<span class="p">)</span>

<span class="n">input_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">put_tensor</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">input_data</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">run_model</span><span class="p">(</span><span class="s2">&quot;keras_fcn&quot;</span><span class="p">,</span> <span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="s2">&quot;output&quot;</span><span class="p">)</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="onnx">
<h2>4.3 ONNX<a class="headerlink" href="#onnx" title="Permalink to this headline">¶</a></h2>
<p>ONNX is a standard format for representing models. A number of different Machine Learning
Libraries are supported by ONNX and can be readily used with SmartSim.</p>
<p>Some popular ones are:</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org">Scikit-learn</a></p></li>
<li><p><a class="reference external" href="https://xgboost.readthedocs.io">XGBoost</a></p></li>
<li><p><a class="reference external" href="https://catboost.ai">CatBoost</a></p></li>
<li><p><a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a></p></li>
<li><p><a class="reference external" href="https://keras.io/">Keras</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/">PyTorch</a></p></li>
<li><p><a class="reference external" href="https://lightgbm.readthedocs.io/en/latest/">LightGBM</a></p></li>
<li><p><a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">libsvm</a></p></li>
</ul>
</div></blockquote>
<p>As well as some that are not listed. There are also many tools to help convert
models to ONNX.</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://github.com/onnx/onnxmltools">onnxmltools</a></p></li>
<li><p><a class="reference external" href="https://github.com/onnx/sklearn-onnx/">skl2onnx</a></p></li>
<li><p><a class="reference external" href="https://github.com/onnx/tensorflow-onnx/">tensorflow-onnx</a></p></li>
</ul>
</div></blockquote>
<p>And PyTorch has its own converter.</p>
<p>Below are some examples of a few models in <a class="reference external" href="https://scikit-learn.org">Scikit-learn</a> that are converted
into ONNX format for use with SmartSim. To use ONNX in SmartSim, specify
<code class="docutils literal notranslate"><span class="pre">ONNX</span></code> as the argument for <em>backend</em> in the call to <code class="docutils literal notranslate"><span class="pre">client.set_model</span></code> or
<code class="docutils literal notranslate"><span class="pre">client.set_model_from_file</span></code>.</p>
<p>These scripts can be used with the <a class="reference internal" href="#infrastructure-code"><span class="std std-ref">SmartSim code</span></a>
above to launch an inference session with any of the supported ONNX libraries.</p>
<section id="kmeans">
<h3>KMeans<a class="headerlink" href="#kmeans" title="Permalink to this headline">¶</a></h3>
<p>K-means clustering is an unsupervised ML algorithm. It is used to categorize data points
into f groups (“clusters”). Scikit Learn has a built in implementation of K-means clustering
and it is easily converted to ONNX for use with SmartSim through <a class="reference external" href="http://onnx.ai/sklearn-onnx/auto_examples/plot_convert_syntax.html">skl2onnx.to_onnx</a>.</p>
<p>Since the KMeans model returns two outputs, we provide the <code class="docutils literal notranslate"><span class="pre">client.run_model</span></code> call
with two <code class="docutils literal notranslate"><span class="pre">outputs</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">tr</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">tr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">kmeans</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">tr</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">target_opset</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()</span>

<span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># dummy data</span>
<span class="n">client</span><span class="o">.</span><span class="n">put_tensor</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">sample</span><span class="p">)</span>

<span class="n">client</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="s2">&quot;kmeans&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="s2">&quot;ONNX&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">run_model</span><span class="p">(</span><span class="s2">&quot;kmeans&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="s2">&quot;transform&quot;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">client</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s2">&quot;labels&quot;</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="random-forest">
<h3>Random Forest<a class="headerlink" href="#random-forest" title="Permalink to this headline">¶</a></h3>
<p>The Random Forest example uses the Iris dataset from Scikit Learn to train a
RandomForestRegressor. As with the other examples, the skl2onnx function
<a class="reference external" href="http://onnx.ai/sklearn-onnx/auto_examples/plot_convert_syntax.html">skl2onnx.to_onnx</a> is used to convert the model to ONNX format.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">clr</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">clr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">rf_model</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">clr</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">6.4</span><span class="p">,</span> <span class="mf">2.8</span><span class="p">,</span> <span class="mf">5.6</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">rf_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()</span>

<span class="n">client</span><span class="o">.</span><span class="n">put_tensor</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">sample</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="s2">&quot;rf_regressor&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="s2">&quot;ONNX&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">run_model</span><span class="p">(</span><span class="s2">&quot;rf_regressor&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">client</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>
</section>


              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="03_lattice_boltz_analysis.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Online Analysis</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="05_training.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Online training with SmartSim</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Cray Labs<br/>
    
        &copy; Copyright 2021-2022, Hewlett Packard Enterprise.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>